# ğŸ™ï¸ Voice Agent - Assistente Vocale Self-Hosted

Un sistema di assistente vocale WebRTC completamente self-hosted che utilizza:
- **LiveKit** per la comunicazione WebRTC in tempo reale
- **Whisper** (faster-whisper) per la trascrizione vocale
- **Ollama** con il modello `gpt-oss` per le risposte AI
- **TTS selezionabile** per la sintesi vocale in italiano

## ğŸ—ï¸ Architettura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     WebRTC      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚    LiveKit   â”‚
â”‚   Client    â”‚                 â”‚    Server    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚  Voice Agent  â”‚
                               â”‚   (Python)    â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼                        â–¼                        â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  Whisper   â”‚           â”‚   Ollama   â”‚           â”‚    TTS     â”‚
       â”‚   (STT)    â”‚           â”‚   (LLM)    â”‚           â”‚  Engine    â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Requisiti

- **Docker** e **Docker Compose**
- **Python 3.10+**
- **Ollama** installato e in esecuzione
- Modello `gpt-oss` caricato in Ollama (o altro modello a scelta)
- 16GB+ RAM consigliati
- Microfono e altoparlanti

## ğŸš€ Installazione

### 1. Clona e configura

```bash
cd livekit-test

# Copia il file di configurazione
cp env.example .env

# Modifica le variabili se necessario
nano .env
```

### 2. Avvia LiveKit Server

```bash
# Avvia LiveKit e Redis
docker-compose up -d

# Verifica che siano in esecuzione
docker-compose ps
```

### 3. Installa dipendenze Python

```bash
# Crea ambiente virtuale
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# oppure: .\venv\Scripts\activate  # Windows

# Installa dipendenze
pip install -r requirements.txt
```

### 3b. Installazione su server con GPU NVIDIA (CUDA)

Per sfruttare la GPU NVIDIA per VibeVoice e Whisper:

```bash
# Crea ambiente virtuale
python3 -m venv venv
source venv/bin/activate

# Installa PyTorch con supporto CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Installa le altre dipendenze
pip install -r requirements-cuda.txt

# Installa VibeVoice
git clone https://github.com/microsoft/VibeVoice.git
cd VibeVoice && pip install -e . && cd ..

# Verifica che CUDA sia disponibile
python -c "import torch; print('CUDA:', torch.cuda.is_available())"
```

**Nota**: Assicurati di avere i driver NVIDIA e CUDA Toolkit installati sul sistema.

### 4. Scarica modello Piper per italiano (opzionale)

```bash
# Crea directory modelli
mkdir -p models/piper

# Scarica modello italiano
curl -L -o models/piper/it_IT-riccardo-x_low.onnx \
  https://huggingface.co/rhasspy/piper-voices/resolve/main/it/it_IT/riccardo/x_low/it_IT-riccardo-x_low.onnx

curl -L -o models/piper/it_IT-riccardo-x_low.onnx.json \
  https://huggingface.co/rhasspy/piper-voices/resolve/main/it/it_IT/riccardo/x_low/it_IT-riccardo-x_low.onnx.json
```

### 5. Verifica Ollama

```bash
# Assicurati che Ollama sia in esecuzione
ollama list

# Se non hai gpt-oss, puoi usare un altro modello
# Modifica OLLAMA_MODEL in .env
```

## ğŸ® Avvio

### Opzione 1: Tutto insieme

```bash
# Terminal 1: LiveKit (se non giÃ  avviato)
docker-compose up -d

# Terminal 2: Web Server
python server.py

# Terminal 3: Voice Agent
python -m agent.main
```

### Opzione 2: Script di avvio

```bash
# Avvia tutto
./start.sh

# Oppure con lo script Python
python run.py
```

### Accedi all'interfaccia

Apri il browser su: **http://localhost:8080**

## ğŸ”Š Opzioni TTS

| Engine | Self-Hosted | QualitÃ  | VelocitÃ  | Note |
|--------|-------------|---------|----------|------|
| **Piper** | âœ… SÃ¬ | Buona | Veloce | Consigliato per uso locale |
| **Coqui** | âœ… SÃ¬ | Alta | Media | Richiede piÃ¹ risorse |
| **Edge** | âŒ No | Ottima | Veloce | Usa API Microsoft gratuite |
| **Kokoro** | âœ… SÃ¬ | Alta | Media | Multilingua |

Puoi cambiare il TTS in tempo reale dall'interfaccia web.

## âš™ï¸ Configurazione

Modifica il file `.env`:

```env
# LiveKit
LIVEKIT_URL=ws://localhost:7880
LIVEKIT_API_KEY=devkey
LIVEKIT_API_SECRET=secret_dev_key_change_in_production

# Ollama
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=gpt-oss  # Cambia con il tuo modello

# Whisper
WHISPER_MODEL=base  # tiny, base, small, medium, large
WHISPER_LANGUAGE=it
WHISPER_DEVICE=cpu  # o cuda per GPU

# TTS Default
DEFAULT_TTS=piper  # piper, coqui, edge, kokoro

# Server
WEB_PORT=8080
LOG_LEVEL=INFO
```

## ğŸ“ Struttura Progetto

```
livekit-test/
â”œâ”€â”€ docker-compose.yml      # LiveKit + Redis
â”œâ”€â”€ livekit.yaml           # Configurazione LiveKit
â”œâ”€â”€ requirements.txt       # Dipendenze Python
â”œâ”€â”€ env.example           # Template configurazione
â”œâ”€â”€ server.py             # Web server FastAPI
â”œâ”€â”€ run.py                # Script avvio completo
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py         # Gestione configurazione
â”‚   â”œâ”€â”€ main.py           # Agent principale
â”‚   â”œâ”€â”€ stt/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ whisper_stt.py    # Whisper STT
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ ollama_llm.py     # Ollama LLM
â”‚   â””â”€â”€ tts/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base.py           # Interfaccia TTS
â”‚       â”œâ”€â”€ piper_tts.py      # Piper TTS
â”‚       â”œâ”€â”€ coqui_tts.py      # Coqui TTS
â”‚       â”œâ”€â”€ edge_tts_engine.py # Edge TTS
â”‚       â””â”€â”€ kokoro_tts.py     # Kokoro TTS
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ index.html        # Frontend
â”‚   â””â”€â”€ app.js            # Client JavaScript
â””â”€â”€ models/
    â””â”€â”€ piper/            # Modelli Piper locali
```

## ğŸ”§ Risoluzione Problemi

### LiveKit non si avvia
```bash
# Verifica i log
docker-compose logs livekit

# Riavvia
docker-compose down && docker-compose up -d
```

### Errore connessione Ollama
```bash
# Verifica che Ollama sia in esecuzione
curl http://localhost:11434/api/tags

# Se non risponde, avvia Ollama
ollama serve
```

### Whisper lento
- Usa un modello piÃ¹ piccolo: `WHISPER_MODEL=tiny`
- Se hai GPU NVIDIA: `WHISPER_DEVICE=cuda`

### TTS non funziona
- **Piper**: Assicurati di aver scaricato i modelli
- **Coqui**: Potrebbe richiedere download al primo avvio
- **Edge**: Richiede connessione internet

## ğŸ“ API Endpoints

| Endpoint | Metodo | Descrizione |
|----------|--------|-------------|
| `/` | GET | Frontend web |
| `/api/health` | GET | Health check |
| `/api/token` | POST | Genera token LiveKit |
| `/api/tts/engines` | GET | Lista TTS disponibili |
| `/api/tts/{engine}/voices` | GET | Voci per engine |
| `/api/config` | GET | Configurazione pubblica |

## ğŸ¤ Contribuire

1. Fork del repository
2. Crea un branch (`git checkout -b feature/nuova-feature`)
3. Commit (`git commit -am 'Aggiunge nuova feature'`)
4. Push (`git push origin feature/nuova-feature`)
5. Apri una Pull Request

## ğŸ“„ Licenza

MIT License

## ğŸ™ Crediti

- [LiveKit](https://livekit.io/) - WebRTC infrastructure
- [Whisper](https://github.com/openai/whisper) - Speech recognition
- [Ollama](https://ollama.ai/) - Local LLM runtime
- [Piper](https://github.com/rhasspy/piper) - Fast TTS
- [Coqui TTS](https://github.com/coqui-ai/TTS) - Neural TTS
- [Edge TTS](https://github.com/rany2/edge-tts) - Microsoft Edge TTS





