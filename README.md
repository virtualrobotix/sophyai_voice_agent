# ğŸ™ï¸ Voice Agent - Assistente Vocale Self-Hosted

Un sistema di assistente vocale WebRTC completamente self-hosted che utilizza:
- **LiveKit** per la comunicazione WebRTC in tempo reale
- **Whisper** (faster-whisper) per la trascrizione vocale
- **Multi-LLM**: Ollama (locale) o OpenRouter (cloud con 100+ modelli)
- **TTS selezionabile** per la sintesi vocale in italiano
- **PostgreSQL** per persistenza chat e configurazione

## ğŸ—ï¸ Architettura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     WebRTC      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚    LiveKit   â”‚
â”‚   Client    â”‚                 â”‚    Server    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚  Voice Agent  â”‚
                               â”‚   (Python)    â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                             â–¼                             â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Whisper   â”‚              â”‚  LLM Provider  â”‚             â”‚    TTS     â”‚
  â”‚   (STT)    â”‚              â”‚ Ollama/OpenRT  â”‚             â”‚  Engines   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚  PostgreSQL   â”‚
                               â”‚  (Database)   â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Requisiti

- **Docker** e **Docker Compose**
- **Python 3.10+**
- **Ollama** installato e in esecuzione (per LLM locale)
- Modello `gpt-oss` caricato in Ollama (o altro modello a scelta)
- 16GB+ RAM consigliati (32GB per modelli TTS avanzati)
- Microfono e altoparlanti
- **GPU NVIDIA** (opzionale, consigliato per VibeVoice/Chatterbox)

## ğŸš€ Installazione

### 1. Clona e configura

```bash
cd livekit-test

# Copia il file di configurazione
cp env.example .env

# Modifica le variabili se necessario
nano .env
```

### 2. Avvia LiveKit Server

```bash
# Avvia LiveKit e Redis
docker-compose up -d

# Verifica che siano in esecuzione
docker-compose ps
```

### 3. Installa dipendenze Python

```bash
# Crea ambiente virtuale
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# oppure: .\venv\Scripts\activate  # Windows

# Installa dipendenze
pip install -r requirements.txt
```

### 3b. Installazione su server con GPU NVIDIA (CUDA)

Per sfruttare la GPU NVIDIA per VibeVoice, Chatterbox e Whisper:

```bash
# Crea ambiente virtuale
python3 -m venv venv
source venv/bin/activate

# Installa PyTorch con supporto CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Installa le altre dipendenze
pip install -r requirements-cuda.txt

# Installa VibeVoice (opzionale)
git clone https://github.com/microsoft/VibeVoice.git vibevoice_repo
cd vibevoice_repo && pip install -e . && cd ..

# Installa Chatterbox (opzionale)
pip install chatterbox-tts

# Verifica che CUDA sia disponibile
python -c "import torch; print('CUDA:', torch.cuda.is_available())"
```

**Nota**: Assicurati di avere i driver NVIDIA e CUDA Toolkit installati sul sistema.

### 4. Scarica modello Piper per italiano (opzionale)

```bash
# Crea directory modelli
mkdir -p models/piper

# Scarica modello italiano
curl -L -o models/piper/it_IT-riccardo-x_low.onnx \
  https://huggingface.co/rhasspy/piper-voices/resolve/main/it/it_IT/riccardo/x_low/it_IT-riccardo-x_low.onnx

curl -L -o models/piper/it_IT-riccardo-x_low.onnx.json \
  https://huggingface.co/rhasspy/piper-voices/resolve/main/it/it_IT/riccardo/x_low/it_IT-riccardo-x_low.onnx.json
```

### 5. Verifica Ollama

```bash
# Assicurati che Ollama sia in esecuzione
ollama list

# Se non hai gpt-oss, puoi usare un altro modello
# Modifica OLLAMA_MODEL in .env
```

## ğŸ® Avvio

### Opzione 1: Tutto insieme

```bash
# Terminal 1: LiveKit (se non giÃ  avviato)
docker-compose up -d

# Terminal 2: Web Server
python server.py

# Terminal 3: Voice Agent
python -m agent.main
```

### Opzione 2: Script di avvio

```bash
# Avvia tutto
./start.sh

# Oppure con lo script Python
python run.py
```

### Accedi all'interfaccia

Apri il browser su: **http://localhost:8080**

## ğŸ”Š Opzioni TTS

| Engine | Self-Hosted | QualitÃ  | VelocitÃ  | Lingue | Note |
|--------|-------------|---------|----------|--------|------|
| **Piper** | âœ… SÃ¬ | Buona | Veloce | Multi | Consigliato per uso locale, leggero |
| **Coqui** | âœ… SÃ¬ | Alta | Media | Multi | Richiede piÃ¹ risorse |
| **Edge** | âŒ No | Ottima | Veloce | Multi | Usa API Microsoft gratuite |
| **Kokoro** | âœ… SÃ¬ | Alta | Media | Multi | Multilingua, buona qualitÃ  |
| **VibeVoice** | âœ… SÃ¬ | Eccellente | Veloce | 6 | Microsoft, streaming real-time, multi-speaker |
| **Chatterbox** | âœ… SÃ¬ | Eccellente | Media | 23 | Resemble AI, voice cloning, emotion control |

Puoi cambiare il TTS in tempo reale dall'interfaccia web.

### VibeVoice (Microsoft)

TTS espressivo con streaming in tempo reale (~300ms latenza):

- **Modelli**: `realtime` (bassa latenza) o `longform` (alta qualitÃ )
- **Speaker**: 4 speaker disponibili
- **Lingue**: Italiano, Inglese, Cinese, Spagnolo, Francese, Tedesco
- **Richiede GPU** per prestazioni ottimali

```env
VIBEVOICE_MODEL=realtime
VIBEVOICE_LANGUAGE=it
VIBEVOICE_SPEAKER=speaker_1
VIBEVOICE_SPEED=1.0
VIBEVOICE_GPU=true
```

### Chatterbox (Resemble AI)

TTS state-of-the-art con voice cloning e emotion control:

- **Modelli**: `standard`, `multilingual`, `turbo`
- **Lingue**: 23 lingue supportate (incluso Italiano)
- **Voice Cloning**: Clona voce da file audio di riferimento
- **Emotion Control**: Controllo esagerazione e CFG weight

```env
CHATTERBOX_MODEL=multilingual
CHATTERBOX_LANGUAGE=it
CHATTERBOX_DEVICE=auto
# Opzionale: voice cloning
CHATTERBOX_AUDIO_PROMPT_PATH=/path/to/voice.wav
# Opzionale: emotion control
CHATTERBOX_EXAGGERATION=0.5
```

## ğŸ¤– Opzioni LLM

| Provider | Locale | Modelli | Note |
|----------|--------|---------|------|
| **Ollama** | âœ… SÃ¬ | Locali | LLM locale, privacy totale |
| **OpenRouter** | âŒ No | 100+ | Accesso a GPT-4, Claude, Gemini, ecc. |

### OpenRouter

Per usare OpenRouter (accesso a GPT-4, Claude, ecc.):

1. Registrati su [openrouter.ai](https://openrouter.ai)
2. Crea una API key
3. Configura nel file `.env`:

```env
OPENROUTER_API_KEY=sk-or-xxx...
OPENROUTER_MODEL=openai/gpt-4-turbo
```

Modelli consigliati per OpenRouter:
- `openai/gpt-4-turbo` - Veloce e intelligente
- `anthropic/claude-3-opus` - Alta qualitÃ 
- `google/gemini-pro` - Buon rapporto qualitÃ /prezzo
- `mistralai/mistral-7b-instruct` - Economico e veloce

## âš™ï¸ Configurazione

Modifica il file `.env`:

```env
# LiveKit
LIVEKIT_URL=ws://localhost:7880
LIVEKIT_API_KEY=devkey
LIVEKIT_API_SECRET=secret_dev_key_change_in_production

# Ollama
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=gpt-oss  # Cambia con il tuo modello

# OpenRouter (opzionale, alternativa a Ollama)
# OPENROUTER_API_KEY=sk-or-xxx...
# OPENROUTER_MODEL=openai/gpt-3.5-turbo

# Whisper
WHISPER_MODEL=base  # tiny, base, small, medium, large
WHISPER_LANGUAGE=it
WHISPER_DEVICE=cpu  # o cuda per GPU

# TTS Default (piper, coqui, edge, kokoro, vibevoice, chatterbox)
DEFAULT_TTS=piper

# Piper TTS
PIPER_MODEL=it_IT-riccardo-x_low
PIPER_SPEAKER=0

# Edge TTS
EDGE_VOICE=it-IT-DiegoNeural

# Coqui TTS
COQUI_MODEL=tts_models/it/mai_female/glow-tts

# Kokoro TTS
KOKORO_VOICE=it_sara

# VibeVoice TTS (Microsoft)
VIBEVOICE_MODEL=realtime
VIBEVOICE_LANGUAGE=it
VIBEVOICE_SPEAKER=speaker_1
VIBEVOICE_SPEED=1.0
VIBEVOICE_GPU=true

# Chatterbox TTS (Resemble AI)
CHATTERBOX_MODEL=multilingual
CHATTERBOX_LANGUAGE=it
CHATTERBOX_DEVICE=auto

# Video/Vision Analysis (opzionale)
VIDEO_ANALYSIS_ENABLED=true
OPENROUTER_VISION_MODEL=openai/gpt-4-vision-preview
OLLAMA_VISION_MODEL=llava

# Server
WEB_PORT=8080
LOG_LEVEL=INFO
```

## ğŸ“ Struttura Progetto

```
livekit-test/
â”œâ”€â”€ docker-compose.yml       # LiveKit + Redis + PostgreSQL
â”œâ”€â”€ Dockerfile              # Docker build principale
â”œâ”€â”€ Dockerfile.agent        # Docker build per agent
â”œâ”€â”€ livekit.yaml            # Configurazione LiveKit
â”œâ”€â”€ livekit-host.yaml       # Config LiveKit per host
â”œâ”€â”€ livekit-local.yaml      # Config LiveKit locale
â”œâ”€â”€ sip-config.yaml         # Configurazione SIP
â”œâ”€â”€ requirements.txt        # Dipendenze Python
â”œâ”€â”€ requirements-cuda.txt   # Dipendenze con CUDA
â”œâ”€â”€ env.example             # Template configurazione
â”œâ”€â”€ server.py               # Web server FastAPI
â”œâ”€â”€ run.py                  # Script avvio completo
â”œâ”€â”€ tts_server.py           # Server TTS dedicato
â”œâ”€â”€ whisper_server.py       # Server Whisper dedicato
â”œâ”€â”€ start.sh                # Script avvio singolo
â”œâ”€â”€ start_all.sh            # Script avvio tutti i servizi
â”œâ”€â”€ setup_cuda.sh           # Setup CUDA
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py           # Gestione configurazione
â”‚   â”œâ”€â”€ main.py             # Agent principale
â”‚   â”œâ”€â”€ stt/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ whisper_stt.py      # Whisper STT
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ollama_llm.py       # Ollama LLM
â”‚   â”‚   â””â”€â”€ openrouter_llm.py   # OpenRouter LLM
â”‚   â””â”€â”€ tts/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base.py             # Interfaccia TTS base
â”‚       â”œâ”€â”€ piper_tts.py        # Piper TTS
â”‚       â”œâ”€â”€ coqui_tts.py        # Coqui TTS
â”‚       â”œâ”€â”€ edge_tts_engine.py  # Edge TTS (Microsoft)
â”‚       â”œâ”€â”€ kokoro_tts.py       # Kokoro TTS
â”‚       â”œâ”€â”€ vibevoice_tts.py    # VibeVoice TTS (Microsoft)
â”‚       â””â”€â”€ chatterbox_tts.py   # Chatterbox TTS (Resemble AI)
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ database.py         # Gestione PostgreSQL
â”‚   â””â”€â”€ schema.sql          # Schema database
â”œâ”€â”€ config/
â”‚   â””â”€â”€ tts_config.json     # Configurazione TTS
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ index.html          # Frontend principale
â”‚   â”œâ”€â”€ debug.html          # Pagina debug
â”‚   â””â”€â”€ app.js              # Client JavaScript
â”œâ”€â”€ vibevoice_repo/         # Repository VibeVoice (Microsoft)
â”‚   â””â”€â”€ ...
â””â”€â”€ models/
    â””â”€â”€ piper/              # Modelli Piper locali
```

## ğŸ—„ï¸ Database

Il sistema utilizza PostgreSQL per:
- **Persistenza chat**: Salvataggio conversazioni
- **Configurazione dinamica**: Settings modificabili da UI
- **Cronologia messaggi**: Storico completo delle interazioni

### Schema Database

| Tabella | Descrizione |
|---------|-------------|
| `settings` | Configurazione key-value |
| `chats` | Sessioni di conversazione |
| `messages` | Messaggi individuali |

## ğŸ”§ Risoluzione Problemi

### LiveKit non si avvia
```bash
# Verifica i log
docker-compose logs livekit

# Riavvia
docker-compose down && docker-compose up -d
```

### Errore connessione Ollama
```bash
# Verifica che Ollama sia in esecuzione
curl http://localhost:11434/api/tags

# Se non risponde, avvia Ollama
ollama serve
```

### Whisper lento
- Usa un modello piÃ¹ piccolo: `WHISPER_MODEL=tiny`
- Se hai GPU NVIDIA: `WHISPER_DEVICE=cuda`

### TTS non funziona
- **Piper**: Assicurati di aver scaricato i modelli
- **Coqui**: Potrebbe richiedere download al primo avvio
- **Edge**: Richiede connessione internet
- **VibeVoice**: Richiede GPU e installazione da repo Microsoft
- **Chatterbox**: `pip install chatterbox-tts`

### VibeVoice: CUDA non disponibile
```bash
# Verifica CUDA
python -c "import torch; print('CUDA:', torch.cuda.is_available())"

# Se False, installa PyTorch CUDA
pip install torch --index-url https://download.pytorch.org/whl/cu121
```

### Chatterbox: Errore caricamento modello
```bash
# Reinstalla con supporto corretto
pip uninstall chatterbox-tts
pip install chatterbox-tts

# Per macOS con MPS
CHATTERBOX_DEVICE=mps  # nel .env
```

## ğŸ“ API Endpoints

| Endpoint | Metodo | Descrizione |
|----------|--------|-------------|
| `/` | GET | Frontend web |
| `/api/health` | GET | Health check |
| `/api/token` | POST | Genera token LiveKit |
| `/api/tts/engines` | GET | Lista TTS disponibili |
| `/api/tts/{engine}/voices` | GET | Voci per engine |
| `/api/config` | GET | Configurazione pubblica |
| `/api/settings` | GET/POST | Gestione impostazioni |
| `/api/chats` | GET/POST | Gestione chat |
| `/api/chats/{id}/messages` | GET | Messaggi di una chat |

## ğŸ¤ Contribuire

1. Fork del repository
2. Crea un branch (`git checkout -b feature/nuova-feature`)
3. Commit (`git commit -am 'Aggiunge nuova feature'`)
4. Push (`git push origin feature/nuova-feature`)
5. Apri una Pull Request

## ğŸ“„ Licenza

MIT License

## ğŸ™ Crediti

- [LiveKit](https://livekit.io/) - WebRTC infrastructure
- [Whisper](https://github.com/openai/whisper) - Speech recognition
- [Ollama](https://ollama.ai/) - Local LLM runtime
- [OpenRouter](https://openrouter.ai/) - Multi-model LLM API
- [Piper](https://github.com/rhasspy/piper) - Fast TTS
- [Coqui TTS](https://github.com/coqui-ai/TTS) - Neural TTS
- [Edge TTS](https://github.com/rany2/edge-tts) - Microsoft Edge TTS
- [VibeVoice](https://github.com/microsoft/VibeVoice) - Microsoft Real-time TTS
- [Chatterbox](https://github.com/resemble-ai/chatterbox) - Resemble AI TTS
- [Kokoro](https://github.com/hexgrad/kokoro) - Multilingual TTS


